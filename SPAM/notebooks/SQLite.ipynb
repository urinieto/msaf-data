{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sqlite3\n",
      "conn = sqlite3.connect(\"../results/results.sqlite\")\n",
      "c = conn.cursor()\n",
      "params = (.2, .6)\n",
      "c.execute('SELECT * FROM foote_bounds WHERE F05=? AND F3=?', params)\n",
      "print c.fetchall()\n",
      "conn.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[]\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sqlite3\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "conn = sqlite3.connect(\"../results/results.sqlite\")\n",
      "c = conn.cursor()\n",
      "trim = False\n",
      "c.execute('SELECT * FROM mma_bounds WHERE trim=?', (trim,))\n",
      "mma_results = np.asarray(c.fetchall(), dtype=[('track_id', '<U400'), ('F05', float), \n",
      "                    ('P05', float), ('R05', float), ('F3', float),\n",
      "                    ('P3', float), ('R3', float), ('D', float), ('DevA2E', float), ('DevE2A', float),\n",
      "                    ('annot_beat', int), ('feature', 'S10'),\n",
      "                    ('add_params', 'S10'), ('trim', int)])\n",
      "algo_ids = [\"serra\", \"levy\", \"foote\", \"siplca\", \"olda\"]\n",
      "feat_dict = {\n",
      "    'serra' :   'mix',\n",
      "    'levy'  :   'hpcp',\n",
      "    'foote' :   'hpcp',\n",
      "    'siplca':   '',\n",
      "    'olda'  :   ''\n",
      "}\n",
      "for i, algo_id in enumerate(algo_ids):\n",
      "    c.execute('SELECT * FROM %s_bounds WHERE feature=? AND trim=?' % algo_id, (feat_dict[algo_id],trim))\n",
      "    tmp_results = np.asarray(c.fetchall(), dtype=[('track_id', '<U400'), ('F05', float), \n",
      "                    ('P05', float), ('R05', float), ('F3', float),\n",
      "                    ('P3', float), ('R3', float), ('D', float), ('DevA2E', float), ('DevE2A', float),\n",
      "                    ('annot_beat', int), ('feature', 'S10'),\n",
      "                    ('add_params', 'S10'), ('trim', int)])\n",
      "    #print algo_id, len(tmp_results),i, tmp_results[0]\n",
      "    if i == 0:\n",
      "        mgp_results = tmp_results\n",
      "    else:\n",
      "        mgp_results['F05'] = np.mean(np.vstack((mgp_results['F05'], tmp_results['F05'])), axis=0)\n",
      "        mgp_results['F3'] = np.mean(np.vstack((mgp_results['F3'], tmp_results['F3'])), axis=0)\n",
      "        mgp_results['D'] = np.mean(np.vstack((mgp_results['D'], tmp_results['D'])), axis=0)\n",
      "        mgp_results['DevA2E'] = np.mean(np.vstack((mgp_results['DevA2E'], tmp_results['DevA2E'])), axis=0)\n",
      "        mgp_results['DevE2A'] = np.mean(np.vstack((mgp_results['DevE2A'], tmp_results['DevE2A'])), axis=0)\n",
      "\n",
      "# Close SQL connection\n",
      "conn.close()\n",
      "\n",
      "# Sort by track id\n",
      "mma_results = np.sort(mma_results, order='track_id')\n",
      "mgp_results = np.sort(mgp_results, order='track_id')\n",
      "\n",
      "def linear_regression(x, y):\n",
      "    A = array([ x, ones(len(x))])\n",
      "    print A.shape, y.shape\n",
      "    w = np.linalg.lstsq(A.T,y)[0] # obtaining the parameters\n",
      "    line = w[0]*x + w[1] # regression line\n",
      "    \n",
      "    # Compute the r2 goodness of fit test\n",
      "    ssres = np.sum( (y - line)**2 )        # The residual sum\n",
      "    sstot = np.sum( (y - np.mean(y))**2 )  # The null hypothesis\n",
      "    r2 = 1 - ssres/float(sstot)\n",
      "    \n",
      "    return line, r2\n",
      "\n",
      "def moving_average(a, n=3) :\n",
      "    ret = np.cumsum(a, dtype=float, axis=1)\n",
      "    ret[:,n:] = ret[:,n:] - ret[:,:-n]\n",
      "    return ret[:,n - 1:] / n\n",
      "\n",
      "def histogram(x, y):\n",
      "    N = 10\n",
      "    H = np.zeros((10, len(x)))\n",
      "    idx_x = np.argsort(x)\n",
      "    print \"ymax\", y.max()\n",
      "    y = y[idx_x] / y.max()\n",
      "#     y = y[idx_x] / 112.466581286\n",
      "    for i, y_i in enumerate(y):\n",
      "        #print \"element\", x_i, np.histogram(x_i, bins=np.arange(0, 1.1, 1/float(N)))[0].shape\n",
      "        H[:,i] = np.histogram(y[i], bins=np.arange(0, 1.1, 1/float(N)))[0]\n",
      "    H = moving_average(H, n=9)\n",
      "    return H\n",
      "\n",
      "def evaluation(x, y, metric, title='', invert=False):\n",
      "    H = histogram(x, y)\n",
      "    line, r2 = linear_regression(x, y)\n",
      "    \n",
      "    # Plotting\n",
      "    figsize = (3, 1.5)\n",
      "    bottom_margin = 0.3\n",
      "    left_margin = 0.2\n",
      "    plt.rc('text', usetex=True)\n",
      "    plt.rc('font', family='serif')\n",
      "    plt.rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
      "    metric_str = metric\n",
      "    if \"{R2E}\" in metric:\n",
      "        metric_str = \"DevA2E\"\n",
      "    if \"{E2R}\" in metric:\n",
      "        metric_str = \"DevE2A\"\n",
      "    if trim:\n",
      "        metric_str += \"-trim\"\n",
      "    \n",
      "    # Plot linear regression\n",
      "    plt.figure(1, figsize=figsize, dpi=160, facecolor='w', edgecolor='k')\n",
      "    plt.scatter(x, y, s=1)\n",
      "#     plt.plot(x, line, 'b-')\n",
      "    #plt.title(title)\n",
      "    plt.gca().set_xlim(0, max(1,x.max()))\n",
      "    plt.gca().set_ylim(0, max(1,y.max()))\n",
      "    plt.xlabel(r\"MMA_{%s}\" % metric)\n",
      "    plt.ylabel(r\"MGP_{%s}\" % metric)\n",
      "    plt.gcf().subplots_adjust(bottom=bottom_margin, left=left_margin)\n",
      "    #plt.savefig('../paper/plots/correl-%s.pdf' % metric_str, bbox_inches='tight')\n",
      "    plt.show()\n",
      "    \n",
      "    print \"R2 of %s is: %.2f\" % (title, r2*100)\n",
      "    \n",
      "    # Plot Histogram\n",
      "    plt.figure(2, figsize=figsize, dpi=160, facecolor='w', edgecolor='k')\n",
      "    if \"{R2E}\" in metric or \"{E2R}\" in metric:\n",
      "        H = H[::-1, ::-1]\n",
      "    plt.imshow(H, interpolation=\"nearest\", aspect=\"auto\", cmap=\"binary\")\n",
      "    plt.gca().invert_yaxis()\n",
      "    plt.gca().set_yticks(np.arange(0,11,5))\n",
      "    plt.gca().set_yticklabels(np.arange(0,11,5)*10)\n",
      "    #plt.title(title)\n",
      "    plt.xlabel(r\"Tracks sorted by MMA_{%s}\" % metric)\n",
      "    plt.ylabel(r\"Histo bins (\\%)\")\n",
      "    plt.gcf().subplots_adjust(bottom=bottom_margin, left=left_margin)\n",
      "    plt.savefig('../paper/plots/histo-human-%s.pdf' % metric_str, bbox_inches='tight')\n",
      "    plt.show()\n",
      "    \n",
      "\n",
      "# Plot with linear regression\n",
      "print \"End\", len(mma_results[\"F05\"]), len(mgp_results['F05'])\n",
      "# evaluation(mma_results['F05'], mgp_results['F05'], 'F05', 'F-measure 0.5 sec')\n",
      "# evaluation(mma_results['F3'], mgp_results['F3'], 'F3', 'F-measure 3 sec')\n",
      "# evaluation(mma_results['D'], mgp_results['D'], 'D', 'Information Gain')\n",
      "# evaluation(mma_results['DevA2E'], mgp_results['DevA2E'], '$\\sigma$_{R2E}', 'Median Deviation: Annotation to Estimation')\n",
      "# evaluation(mma_results['DevE2A'], mgp_results['DevE2A'], '$\\sigma$_{E2R}', 'Median Deviation: Estimation to Annotation')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "End 2156 2156\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# HUMANS\n",
      "import pickle\n",
      "import jams2\n",
      "import os\n",
      "\n",
      "mma_results = pickle.load(open(\"../experiment/mma_experiment_humans.pk\", \"r\"))\n",
      "mgp_results = pickle.load(open(\"../experiment/mgp_experiment_humans.pk\", \"r\"))\n",
      "# print mgp_results\n",
      "\n",
      "mgp_results = np.sort(mgp_results, order=\"F3\")\n",
      "durations = []\n",
      "for mgp_res in mgp_results:\n",
      "    jam_file = \"/Users/uri/datasets/Segments/annotations/\" + os.path.basename(mgp_res[\"track_id\"][:-5]) + \".jams\"\n",
      "    jam = jams2.load(jam_file)\n",
      "    durations.append(jam.metadata.duration)\n",
      "plt.figure(1, figsize=(5, 1.9), dpi=160, facecolor='w', edgecolor='k')\n",
      "plt.plot(np.arange(len(durations)), durations)\n",
      "plt.gca().set_xlim([0,50])\n",
      "plt.gca().set_ylim([0,650])\n",
      "plt.xlabel(r\"Tracks sorted by MGP$_{F3}$\")\n",
      "plt.ylabel(r\"Duration (seconds)\")\n",
      "plt.gcf().subplots_adjust(bottom=0.23, left=0.14)\n",
      "plt.show()\n",
      "\n",
      "#evaluation(mma_results['F05'], mgp_results['F05'], 'F05', 'F-measure 0.5 sec')\n",
      "# evaluation(mma_results['F3'], mgp_results['F3'], 'F3', 'F-measure 3 sec')\n",
      "# evaluation(mma_results['D'], mgp_results['D'], 'D', 'Information Gain')\n",
      "# evaluation(mma_results['DevA2E'], mgp_results['DevA2E'], '$\\sigma$_{R2E}', 'Median Deviation: Annotation to Estimation')\n",
      "# evaluation(mma_results['DevE2A'], mgp_results['DevE2A'], '$\\sigma$_{E2R}', 'Median Deviation: Estimation to Annotation')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Find the 45 \"worst\" and 5 \"best\" tracks.\n",
      "import os\n",
      "import jams2\n",
      "\n",
      "total_secs = 0\n",
      "def is_longer(est_file, secs=600):\n",
      "    \"\"\"Checks whether this track is longer than 'secs' seconds.\"\"\"\n",
      "    jam_file = \"/Users/uri/datasets/Segments/annotations/\" + est_file[:-5] + \".jams\"\n",
      "    jam = jams2.load(jam_file)\n",
      "    global total_secs\n",
      "    total_secs += jam.metadata.duration\n",
      "    if jam.metadata.duration > secs:\n",
      "        return True\n",
      "    return False\n",
      "\n",
      "# Plot duration\n",
      "# mgp_results = np.sort(mgp_results, order=\"F3\")\n",
      "# durations = []\n",
      "# for mgp_res in mgp_results:\n",
      "#     jam_file = \"/Users/uri/datasets/Segments/annotations/\" + mgp_res[\"track_id\"][:-5] + \".jams\"\n",
      "#     jam = jams2.load(jam_file)\n",
      "#     durations.append(jam.metadata.duration)\n",
      "# plt.figure(1, figsize=(5, 1.9), dpi=160, facecolor='w', edgecolor='k')\n",
      "# plt.plot(np.arange(len(durations)), durations)\n",
      "# plt.gca().set_xlim([0,2154])\n",
      "# plt.gca().set_ylim([0,1850])\n",
      "# plt.xlabel(r\"Tracks sorted by MGP$_{F3}$\")\n",
      "# plt.ylabel(r\"Duration (seconds)\")\n",
      "# plt.gcf().subplots_adjust(bottom=0.23, left=0.14)\n",
      "# plt.show()\n",
      "\n",
      "# Find bad results\n",
      "# bad = ['SALAMI_718.json', 'SALAMI_714.json', 'SALAMI_1376.json', 'SALAMI_720.json', 'SALAMI_378.json', 'SALAMI_724.json', 'SALAMI_710.json']\n",
      "# for mgp_res in mgp_results:\n",
      "#     if is_longer(mgp_res['track_id'], secs=600):\n",
      "#         bad.append(mgp_res['track_id'])\n",
      "        \n",
      "# print \"Total Seconds in dataset\", total_secs, total_secs/float(len(mgp_results)), len(mgp_results)\n",
      "\n",
      "# metric = 'F3'\n",
      "# # mgp_results = np.sort(mgp_results, order=metric)\n",
      "# # for mgp_res in mgp_results[:45]:\n",
      "# #     if is_longer(mgp_res['track_id'], secs=600):\n",
      "# #         print \"Longer inside\"\n",
      "# #     if mgp_res['track_id'] in bad:\n",
      "# #         print \"SALAMI speech\"\n",
      "# res = filter(lambda x: x[\"track_id\"] not in bad, mgp_results)\n",
      "# filtered_good = np.sort(res, order=metric)[-5:]\n",
      "# filtered = np.sort(res, order=metric)[:45]\n",
      "# #print np.sort(filtered, order='track_id')\n",
      "\n",
      "# subset_secs = 0\n",
      "# for filt in filtered:\n",
      "#     jam_file = \"/Users/uri/datasets/Segments/annotations/\" + filt[\"track_id\"][:-5] + \".jams\"\n",
      "#     jam = jams2.load(jam_file)\n",
      "#     subset_secs += jam.metadata.duration\n",
      "    \n",
      "# print \"Total Seconds in subset\", subset_secs, subset_secs/float(len(filtered)), len(filtered)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "IOError",
       "evalue": "[Errno 2] No such file or directory: u'/Users/uri/datasets/Segments/annotations//Users/uri/datasets/SubSegments/annotations/Cerulean_Yes-Starship_Trooper:_A._Life_Seeker,_B._Disillu.jams'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-54-aa44c76e45ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmgp_res\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmgp_results\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mjam_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/Users/uri/datasets/Segments/annotations/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmgp_res\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"track_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".jams\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mjam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjams2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjam_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mdurations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mduration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m160\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfacecolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medgecolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'k'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/uri/NYU/Dissertation/jams2/fileio.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(filepath)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;34m\"\"\"Load a JSON formatted stream from a file.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mfpointer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mJams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpointer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: u'/Users/uri/datasets/Segments/annotations//Users/uri/datasets/SubSegments/annotations/Cerulean_Yes-Starship_Trooper:_A._Life_Seeker,_B._Disillu.jams'"
       ]
      }
     ],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Clean up mma table (there are SALAMI tracks without ground truth)\n",
      "import sqlite3\n",
      "conn = sqlite3.connect(\"../results/results.sqlite\")\n",
      "c = conn.cursor()\n",
      "feat_dict = {\n",
      "    'serra' :   'mix',\n",
      "    'levy'  :   'mfcc',\n",
      "    'foote' :   'hpcp',\n",
      "    'siplca':   '',\n",
      "    'olda'  :   ''\n",
      "}\n",
      "tracks = []\n",
      "trim = True\n",
      "for algo_id in [\"serra\", \"levy\"]:\n",
      "    c.execute('SELECT track_id FROM %s_bounds WHERE feature=? AND trim=?' % algo_id, (feat_dict[algo_id],trim))\n",
      "    tracks.append(c.fetchall())\n",
      "serra = set(tracks[0])\n",
      "levy = set(tracks[1])\n",
      "print serra ^ levy\n",
      "\n",
      "c.execute('SELECT track_id FROM mma_bounds')\n",
      "mma = set(c.fetchall())\n",
      "to_delete = mma ^ serra\n",
      "for track in to_delete:\n",
      "    c.execute('DELETE FROM mma_bounds WHERE track_id=?', track)\n",
      "    print track\n",
      "conn.commit()\n",
      "conn.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "set([])\n",
        "(u'SALAMI_1320.json',)\n",
        "(u'SALAMI_1052.json',)\n",
        "(u'SALAMI_1466.json',)\n",
        "(u'SALAMI_918.json',)\n",
        "(u'SALAMI_1440.json',)\n",
        "(u'SALAMI_872.json',)\n",
        "(u'SALAMI_1430.json',)\n",
        "(u'SALAMI_1126.json',)\n",
        "(u'SALAMI_1500.json',)\n",
        "(u'SALAMI_1140.json',)\n",
        "(u'SALAMI_1040.json',)\n",
        "(u'SALAMI_966.json',)\n",
        "(u'SALAMI_1486.json',)\n",
        "(u'SALAMI_1398.json',)\n",
        "(u'SALAMI_1030.json',)\n",
        "(u'SALAMI_1410.json',)\n",
        "(u'SALAMI_1426.json',)\n",
        "(u'SALAMI_1178.json',)\n"
       ]
      }
     ],
     "prompt_number": 69
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Binary entropy\n",
      "score = 0.5\n",
      "scores = np.asarray([score, 1-score])\n",
      "entropy = 0\n",
      "for s in scores:\n",
      "    entropy += s*np.log2(s)\n",
      "entropy *= -1\n",
      "print entropy\n",
      "print filtered[\"track_id\"], len(filtered[\"track_id\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1.0\n",
        "[u'SALAMI_546.json' u'Isophonics_02 Under Pressure.json'\n",
        " u'Isophonics_01 The Show Must Go On.json' u'SALAMI_68.json'\n",
        " u'SALAMI_830.json'\n",
        " u'Cerulean_Yes-Starship_Trooper:_A._Life_Seeker,_B._Disillu.json'\n",
        " u'SALAMI_1472.json' u'SALAMI_1482.json'\n",
        " u'Cerulean_Bob_Dylan-Like_a_Rolling_Stone_(Live).json'\n",
        " u'Isophonics_09_-_You_Never_Give_Me_Your_Money.json' u'SALAMI_1072.json'\n",
        " u\"Isophonics_CD1_-_14_-_Don't_Pass_Me_By.json\" u'SALAMI_444.json'\n",
        " u'Isophonics_05 Somebody To Love.json'\n",
        " u'Isophonics_CD2_-_06_-_Helter_Skelter.json' u'SALAMI_458.json'\n",
        " u'SALAMI_868.json' u'Isophonics_14 Smackwater Jack [Live].json'\n",
        " u'SALAMI_1468.json'\n",
        " u'Cerulean_Leonard_Bernstein,_New_York_Philharmonic_&_Rudol.json'\n",
        " u'SALAMI_812.json'\n",
        " u'Cerulean_Boston_Symphony_Orchestra_&_Charles_Munch-Sympho.json'\n",
        " u'SALAMI_286.json' u'SALAMI_944.json' u'SALAMI_1324.json'\n",
        " u'SALAMI_758.json' u'SALAMI_1152.json' u'SALAMI_1270.json'\n",
        " u'SALAMI_308.json' u'SALAMI_12.json' u'SALAMI_542.json' u'SALAMI_940.json'\n",
        " u'SALAMI_876.json' u'SALAMI_1130.json' u'SALAMI_728.json'\n",
        " u'SALAMI_164.json' u'Cerulean_Miles_Davis_Quintet-Footprints.json'\n",
        " u'SALAMI_584.json' u'SALAMI_1000.json'\n",
        " u'Cerulean_Bob_Dylan-Hurricane.json' u'SALAMI_1240.json'\n",
        " u'SALAMI_882.json' u'SALAMI_1448.json'\n",
        " u'Cerulean_Prince_&_The_Revolution-Purple_Rain.json' u'SALAMI_78.json'] 45\n"
       ]
      }
     ],
     "prompt_number": 82
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Copy the subdataset to ~/datasets/SubSegments\n",
      "\n",
      "import shutil\n",
      "import os\n",
      "import jams\n",
      "import json\n",
      "\n",
      "def copy_files(files):\n",
      "    for f in files:\n",
      "        # Audio\n",
      "        src = \"/Users/uri/datasets/Segments/audio/\" + f[\"track_id\"][:-5] + \".mp3\"\n",
      "        dest = \"/Users/uri/datasets/SubSegments/audio/\" + os.path.basename(src)\n",
      "        shutil.copy(src, dest)\n",
      "        \n",
      "        # Annotations\n",
      "        src = \"/Users/uri/datasets/Segments/annotations/\" + f[\"track_id\"][:-5] + \".jams\"\n",
      "        jam = jams.load(src)\n",
      "        #jam.sections = [] # Remove all section annotations (we only care about the metadata) # UPDATE: Not true!\n",
      "        for annot in jam.sections:\n",
      "            annot.annotation_metadata.annotator.name = \"GT\"  # Call the annotator \"GT\"\n",
      "        dest = \"/Users/uri/datasets/SubSegments/annotations/\" + os.path.basename(src)\n",
      "        with open(dest, \"w\") as f:\n",
      "            json.dump(jam, f, indent=2)\n",
      "\n",
      "copy_files(filtered)\n",
      "copy_files(filtered_good)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print np.mean(filtered[\"F3\"]), np.mean(filtered[\"F05\"]), filtered.shape, filtered_good.shape\n",
      "merged = np.append(filtered, filtered_good, axis=0)\n",
      "for filt in merged:\n",
      "    print filt[\"track_id\"], filt[\"F3\"], filt[\"DevA2E\"]\n",
      "import pickle\n",
      "#pickle.dump(merged, open(\"mgp_experiment_machine.pk\", \"w\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.270176197771 0.189591116707 (45,) (5,)\n",
        "SALAMI_546.json 0.200844626388 1.96698953528\n",
        "Isophonics_02 Under Pressure.json 0.21368006993 11.2496330443\n",
        "Isophonics_01 The Show Must Go On.json 0.230300605192 8.28406908684\n",
        "SALAMI_68.json 0.230766377697 0.448315429895\n",
        "SALAMI_830.json 0.241028295376 0.39388045725\n",
        "Cerulean_Yes-Starship_Trooper:_A._Life_Seeker,_B._Disillu.json 0.24621284072 14.8982950081\n",
        "SALAMI_1472.json 0.247552104678 15.8240720892\n",
        "SALAMI_1482.json 0.25118498417 8.53194592761\n",
        "Cerulean_Bob_Dylan-Like_a_Rolling_Stone_(Live).json 0.252962011648 36.1585672042\n",
        "Isophonics_09_-_You_Never_Give_Me_Your_Money.json 0.254643912963 5.89547148519\n",
        "SALAMI_1072.json 0.25535408072 27.5903004205\n",
        "Isophonics_CD1_-_14_-_Don't_Pass_Me_By.json 0.255428970007 8.13095029838\n",
        "SALAMI_444.json 0.25580894146 10.6345364634\n",
        "Isophonics_05 Somebody To Love.json 0.256420275282 8.00841285774\n",
        "Isophonics_CD2_-_06_-_Helter_Skelter.json 0.257052957935 12.5014932569\n",
        "SALAMI_458.json 0.258506938234 4.58800824429\n",
        "SALAMI_868.json 0.264371679436 14.3667829664\n",
        "Isophonics_14 Smackwater Jack [Live].json 0.265064102564 13.6847123755\n",
        "SALAMI_1468.json 0.265317409411 4.49913092387\n",
        "Cerulean_Leonard_Bernstein,_New_York_Philharmonic_&_Rudol.json 0.265900436144 4.34910873716\n",
        "SALAMI_812.json 0.267112376352 14.5518398676\n",
        "Cerulean_Boston_Symphony_Orchestra_&_Charles_Munch-Sympho.json 0.267165551839 6.28206599829\n",
        "SALAMI_286.json 0.268283371041 9.26491296585\n",
        "SALAMI_944.json 0.271415327893 14.8367286815\n",
        "SALAMI_1324.json 0.272234320557 15.1427010003\n",
        "SALAMI_758.json 0.283242853638 3.05487542921\n",
        "SALAMI_1152.json 0.285931876234 19.1925680364\n",
        "SALAMI_1270.json 0.286436100132 5.71416974484\n",
        "SALAMI_308.json 0.286874303278 8.39882629327\n",
        "SALAMI_12.json 0.287987012987 1.08064729192\n",
        "SALAMI_542.json 0.28845254792 1.45189515144\n",
        "SALAMI_940.json 0.288923731165 3.45262414015\n",
        "SALAMI_876.json 0.288934652808 5.89522148381\n",
        "SALAMI_1130.json 0.288980767928 10.7628228415\n",
        "SALAMI_728.json 0.289212359121 10.2351546608\n",
        "SALAMI_164.json 0.290174220273 2.14556122975\n",
        "Cerulean_Miles_Davis_Quintet-Footprints.json 0.295395576646 8.413942909\n",
        "SALAMI_584.json 0.295445526696 1.43745644573\n",
        "SALAMI_1000.json 0.295454545455 7.20012975514\n",
        "Cerulean_Bob_Dylan-Hurricane.json 0.297326251717 31.0546130568\n",
        "SALAMI_1240.json 0.29768143475 6.86862279213\n",
        "SALAMI_882.json 0.298386486702 2.5075090965\n",
        "SALAMI_1448.json 0.298710576936 9.37154689527\n",
        "Cerulean_Prince_&_The_Revolution-Purple_Rain.json 0.299771421108 16.2228284537\n",
        "SALAMI_78.json 0.299994086584 0.55736946296\n",
        "Epiphyte_0537_writteninthestars.json 0.774464570517 1.47998361549\n",
        "Isophonics_12_-_Polythene_Pam.json 0.779541292041 1.98210540028\n",
        "Epiphyte_0298_turnmeon.json 0.783164983165 0.949352259036\n",
        "Epiphyte_0220_promiscuous.json 0.790323004202 2.07247616025\n",
        "Epiphyte_0195_nookie.json 0.807383309632 1.00601805238\n"
       ]
      }
     ],
     "prompt_number": 83
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}